# Virtual Memory

## 가상 메모리 기술

가상 메모리는 컴퓨터 시스템에서 사용되는 메모리 관리 기술입니다.
물리적 메모리(RAM)와 보조 저장장치(일반적으로 하드 디스크)를 결합하여 프로세스에 연속적이고 큰 주소 공간을 제공합니다.

가상 메모리는 다음과 같은 주요 목적을 가집니다:

1. 물리적 메모리 크기의 제한을 극복
2. 프로세스 간 메모리 보호 제공
3. 메모리 관리 및 프로그램 로딩 단순화
4. 다중 프로그래밍 환경 지원

가상 메모리 시스템은 각 프로세스에 가상 주소 공간을 제공합니다.
이 가상 주소 공간은 물리적 메모리의 실제 크기보다 클 수 있습니다.
운영 체제는 Memory Management Unit (MMU)을 사용하여 가상 주소를 물리적 주소로 변환합니다.

## 주소 변환 과정

1. 프로세스가 가상 주소를 참조합니다.
2. MMU가 페이지 테이블을 검사하여 해당 가상 페이지가 물리적 메모리에 있는지 확인합니다.
3. 페이지가 메모리에 있으면(페이지 히트), 물리적 주소로 변환하여 접근합니다.
4. 페이지가 메모리에 없으면(페이지 폴트), 운영 체제가 개입하여 페이지를 보조 저장장치에서 메모리로 로드합니다.

가상 메모리의 핵심 원리에 대해 더 깊이 있고 기술적으로 정확한 설명을 제공하겠습니다.

## 주소 변환 (Address Translation)

주소 변환은 가상 메모리 시스템의 근간으로, 프로세스가 사용하는 가상 주소를 물리적 메모리의 실제 주소로 매핑하는 과정입니다.

- 페이지 테이블 (Page Table): 각 프로세스마다 유지되며, 가상 페이지 번호를 물리적 페이지 번호로 매핑합니다.
- TLB (Translation Lookaside Buffer): 최근 사용된 페이지 테이블 엔트리의 캐시로, 주소 변환 속도를 향상시킵니다.
- MMU (Memory Management Unit): 하드웨어 컴포넌트로, 실제 주소 변환을 수행합니다.

주소 변환 과정은 다음과 같습니다.

1. 프로세스가 가상 주소 `v`를 참조
2. `v`를 가상 페이지 번호(VPN, Virtual Page Number)와 오프셋으로 분할
3. MMU가 TLB(Translation Lookaside Buffer)에서 VPN 검색
4. TLB
    - hit: 물리적 페이지 번호(PPN, Physical Page Number) 즉시 반환
    - miss: 페이지 테이블에서 VPN 검색
5. 페이지 테이블에서 물리적 페이지 번호(PPN, Physical Page Number) 획득
6. 물리적 페이지 번호(PPN, Physical Page Number)와 오프셋을 조합하여 물리적 주소 `p` 생성
7. 물리적 주소 `p`로 메모리 접근

## 페이징 (Paging)

페이징은 물리적 메모리와 가상 메모리를 동일한 크기의 블록(페이지)으로 나누어 관리하는 기법입니다.
1. 가상 주소 공간과 물리적 메모리를 동일한 크기의 블록(페이지)으로 나눕니다.
2. 페이지 테이블을 사용하여 가상 페이지와 물리적 페이지 간의 매핑을 관리합니다.
3. 필요한 페이지만 물리적 메모리에 로드하고, 나머지는 보조 저장장치에 유지합니다.

x86-64 아키텍처에서의 페이지 테이블 엔트리 (PTE)는 대략적으로 다음과 같은 필드들을 가집니다:

```plaintext
|  P (1 bit) |  RW (1 bit)  |  US (1 bit)  |  PWT (1 bit)  |  PCD (1 bit)  |  A (1 bit)  |  D (1 bit)  |  PS (1 bit)  |  XD (1 bit)  |  Physical Page Frame Number (40 bits)  |
```

- Present bit (P), 또는 Valid bit:

    해당 PTE가 유효한지 여부를 나타냅니다.
    - 1이면 유효한 페이지로, 현재 메모리에 로드되어 있고, 접근할 수 있음을 의미합니다.
    - 0이면 유효하지 않으며, 페이지 폴트가 발생할 수 있습니다.

- Read/Write bit (RW) 또는 Protection bits:

    해당 페이지에 대해 쓰기 권한을 허용하는지를 나타냅니다. 읽기는 기본적으로 허용됩니다.
    이러한 권한을 기반으로 운영체제는 접근을 제한하거나 허용하며, 권한 위반 시 페이지 폴트가 발생합니다.

- User/Supervisor bit (US):

    사용자 모드(ring 3) 프로세스가 해당 페이지에 접근할 수 있는지를 나타냅니다.
    0이면 커널 모드(ring 0)에서만 접근 가능합니다.

- Page-level write-through (PWT): 쓰기 스루 캐싱 여부.
- Page-level cache disable (PCD): 캐싱 비활성화 여부.
- Accessed bit (A):

    해당 페이지가 최근에 참조되었는지를 나타냅니다.
    페이지 교체 알고리즘(예: LRU, Clock 등)에서 페이지의 사용 여부를 추적하는 데 사용됩니다.
    참조되면 이 비트가 1로 설정됩니다.

- Dirty bit (D):

    페이지가 수정되었는지를 나타냅니다.
    페이지가 수정되었으면 이 비트가 1로 설정됩니다.
    메모리 매핑된 파일이나 스왑 파일 등의 경우, 페이지가 수정되었다면 백업 스토리지에 다시 기록해야 하므로 이를 추적하기 위해 사용됩니다.

- Page size (PS):

    페이지 크기(4KB 또는 2MB).
    이 비트는 대형 페이지(2MB 또는 1GB)를 사용할 때 설정됩니다.
    대형 페이지는 TLB 효율성을 높이고 페이지 테이블 오버헤드를 줄이는 데 사용됩니다.

- Physical page frame number:

    페이지 테이블 엔트리는 가상 주소를 물리 주소로 변환하는 역할을 합니다.
    이 필드는 가상 주소와 대응하는 물리 페이지의 번호를 나타냅니다.

    일반적으로 페이지의 물리적 주소는 페이지 크기(예: 4KB)에 맞춰 정렬되기 때문에 상위 비트에만 물리 페이지 번호가 저장되고, 하위 비트는 0으로 채워집니다.

- Execute Disable bit (XD): 실행 방지.

### 페이지 교체 알고리즘

1. LRU (Least Recently Used):
    가장 오랫동안 사용되지 않은 페이지 교체

    구현: 각 페이지에 대한 타임스탬프 또는 카운터 유지

2. Clock 알고리즘:
    LRU의 근사 알고리즘, 순환 버퍼와 참조 비트 사용

    구현: 원형 리스트로 페이지 관리, 참조 비트로 사용 여부 표시

3. FIFO (First-In-First-Out):
    가장 오래된 페이지 교체

    구현: 큐 자료구조 사용

### 다단계 페이지 테이블

대용량 주소 공간을 효율적으로 관리하기 위해 사용됩니다.

```plaintext
Level 1 Page Table -> Level 2 Page Table -> ... -> Level n Page Table -> Physical Page
```

각 레벨의 페이지 테이블은 다음 레벨의 페이지 테이블 주소를 가리킵니다.

### 페이지 폴트 처리 과정

1. MMU (Memory Management Unit)가 페이지 폴트 감지 및 트랩 발생
2. 운영 체제의 페이지 폴트 핸들러 호출
3. 보조 저장장치에서 요청된 페이지 위치 확인
4. 빈 물리적 페이지 프레임 할당 (필요시 페이지 교체)
5. 보조 저장장치에서 페이지 데이터 읽기
6. 페이지 테이블 업데이트
7. 프로세스 재개

## 스와핑 (Swapping)

스와핑은 물리적 메모리와 보조 저장장치(일반적으로 디스크) 사이에서 페이지를 이동하는 메커니즘입니다.

## 스래싱 (Thrashing) 방지

스래싱이란 과도한 페이지 폴트로 인해 실제 작업보다 페이지 교체에 더 많은 시간을 소비하는 현상을 의미합니다.

이를 방지하는 기법은 다음과 같습니다:
1. 작업 세트 모델 (Working Set Model) 사용
2. 페이지 폴트 빈도 모니터링
3. 로컬 교체 정책 적용

## 가상 메모리의 장단점

### 장점

1. 물리적 메모리 크기 제한 극복
2. 프로세스 간 메모리 보호 강화
3. 메모리 관리 및 프로그램 로딩 단순화
4. 메모리 사용 효율성 향상

### 단점

1. 주소 변환으로 인한 성능 오버헤드
2. 페이지 폴트 처리 시 지연 발생
3. 페이지 테이블로 인한 추가 메모리 사용

## 가상 메모리 응용

가상 주소는 다음과 같은 경우에 소비될 수 있습니다.
- 파일을 메모리에 매핑(`mmap`)하면 가상 주소 공간을 소비합니다. 실제 사용 여부와 관계없이 매핑된 크기만큼 가상 주소 공간이 할당됩니다.
- malloc으로 대량의 메모리를 할당하면, 실제 사용 여부와 관계없이 가상 주소 공간을 소비합니다.
- 로드된 각 공유 라이브러리는 가상 주소 공간의 일부를 차지합니다.
- 각 스레드는 별도의 스택을 가지며, 이는 가상 주소 공간을 소비합니다.

### 파일 맵(file map)

일반적으로 프로세스가 파일에 접근할 떄는 파일을 연 뒤에 `read`, `write`, `lseek` 등의 시스템 콜을 사용합니다.
뿐만 아니라 리눅스에서는 파일의 영역을 가상 주소 공간에 메모리 맵핑하는 기능이 있습니다.

맵핑된 파일은 메모리 접근과 같은 방식으로 접근이 가능합니다.

### demand paging

디맨드 페이징이 아닌 경우, '프로세스 생성' 시 또는 '프로세스 생성 후 `mmap` 시스템 콜로 프로세스에 메모리를 할당할 때' 다음과 같은 순서로 진행됩니다.
1. 커널이 필요한 영역을 메모리에 확보합니다.
    물리 메모리가 즉시 할당됩니다.

2. 커널이 페이지 테이블을 설정하여 가상 주소 공간을 물리 주소 공간에 맵핑합니다.
    페이지 테이블 엔트리는 유효(valid)하고 존재(present)하는 상태로 설정됩니다.
    모든 페이지가 미리 물리 메모리에 로드되므로, 실행 중 페이지 폴트가 발생하지 않습니다.

하지만 메모리 확보 후 프로세스 종료할 때까지 사용되지 않는 영역이 있을 수 있으므로, 메모리를 낭비하는 단점이 있습니다.
- 커다란 프로그램 중 실행에 사용하지 않는 기능을 위한 코드 영역과 데이터 영역
- glibc가 확보한 메모리 맵 중 유저가 `malloc` 함수로 확보하지 않은 부분

반면 디맨드 페이징은 다음과 같은 순서로 진행됩니다.
1. 프로세스의 가상 주소 공간 안에 코드 영역이나 데이터 영역에 대응하는 페이지에 `프로세스가 이 영역을 얻었음`이라는 정보를 기록합니다. 그러나 물리 메모리는 이 시점에는 할당되지 않습니다.
    페이지 테이블 엔트리는 초기에 무효(invalid) 또는 미존재(not present) 상태로 설정됩니다.

2. 프로그램이 엔트리 포인트로부터 실행을 시작할 때에는 엔트리 포인트에 대응하는 페이지용 물리 메모리가 할당됩니다.
    1. 프로그램이 엔트리 포인트에 접근합니다.
    2. CPU가 페이지 테이블을 참조해서 엔드리 포인트가 속한 페이지에 대응하는 가상 주소가 물리 주소에 아직 맵핑되지 않음을 확인합니다.
    3. CPU에 페이지 폴트가 발생합니다.
    4. 커널의 페이지 폴트 핸들러에 의해 접근 시도했던 해당 페이지에 물리 메모리를 할당하고, 페이지 테이블 업데이트하고, 페이지 폴트를 지웁니다.
    5. 사용자 모드로 돌아와서 프로세스가 실행을 계속합니다.

    마찬가지로 아직 할당되지 않은 다른 영역에 접근하게 되면 위와 같은 처리를 반복합니다.

프로세스가 `mmap` 함수 등을 이용하여 메모리를 확보하는 것을 `가상 메모리를 확보했음`이라고 합니다.
그리고 확보한 가상 메모리에 접근하여 물리 메모리를 확보하고 맵핑하는 것을 `물리 메모리를 확보했음`이라고 합니다.

디맨드 페이징을 사용하면 프로세스의 가상 주소 공간 내의 각 페이지에 대응하는 주소는 페이지에 처음 접근할 때 할당됩니다.
`프로세스에는 할당되지 않음` 또는 `프로세스에는 할당되었으며 물리메모리에도 할당되었음` 외에
`프로세스에는 할당되었지만 물리 메모리에는 할당되지 않음`이라는 새로운 상태를 추가합니다.

### 가상 주소 공간이 부족해지는 케이스

가령 x86 아키텍처 32비트 시스템에 2^32는 주소의 개수를 나타내며, 각 주소는 1바이트를 가리킵니다.
따라서 32비트 시스템에서 프로세스가 사용할 수 있는 가상 주소 공간은 $2^{32} \times 1 \; byte$, 즉 4GB로 제한됩니다.
이는 32비트로 표현할 수 있는 최대 주소 범위입니다.

$$
2^{32} = 4,294,967,296 \text{ 바이트} \approx 4\text{ GB}
$$

따라서 가령 DB 같은 큰 규모의 프로그램 사용 시 다음과 같은 경우 종종 발생할 수 있습니다.
1. 대용량 버퍼 풀:

    데이터베이스는 성능 향상을 위해 대규모 버퍼 풀을 메모리에 유지합니다.
    예를 들어, 2GB 크기의 버퍼 풀을 할당하면, 가상 주소 공간의 절반을 즉시 소비합니다.

2. 메모리 매핑된 파일:

    데이터 파일을 메모리에 매핑하여 빠른 접근을 제공합니다.
    예를 들어, 여러 1GB 데이터 파일을 매핑하면, 각 파일마다 1GB의 가상 주소 공간을 소비합니다.

3. 쿼리 실행 공간:

    복잡한 쿼리 실행을 위한 임시 작업 공간이 필요합니다.
    정렬, 해시 조인 등의 작업은 대량의 메모리를 일시적으로 요구할 수 있습니다.

4. 연결 및 세션 관리:

    각 클라이언트 연결은 메모리를 소비하며, 이는 가상 주소 공간에 반영됩니다.

5. 캐시 및 인덱스:

    빠른 데이터 접근을 위한 캐시와 인덱스 구조가 메모리에 유지됩니다.

### COW(Copy on Write) 방식의 고속 프로세스 생성

`fork` 시스템 콜도 가상 메모리 방식을 사용해서 고속화됩니다.
호출했을 때가 아닌 그 후 쓰기가 발생할 때 물리 메모리를 복사하기 때문에 이 방식을 Copy on Write라고 합니다.

`fork` 시스템 콜을 수행할 떄는 부모 프로세스와 메모리를 자식 프로세스에 전부 복사하지 않고 페이지 테이블만 복사합니다.
페이지 테이블 엔트리 안에는 쓰기 권한을 나타내는 필드가 있지만, 이 경우 부모도 자식도 전체 페이지에 쓰기 권한을 무효화 합니다.

이후에 페이지를 읽을 뿐이라면 어느 쪽의 프로세스도 공유된 물리 페이지에 접근할 수 있습니다.
하지만 부모 또는 자식 프로세스 어느 쪽이든 페이지의 어딘가를 변경하려고 하면 다음과 같은 흐름으로 공유를 해제합니다.
1. 페이지에 쓰기는 허용하지 않기 때문에 쓰려고 할 떄 CPU에 페이지 폴트가 발생합니다.
2. CPU가 커널 모드로 변경되어 커널의 페이지 폴트 핸들러가 동작합니다.
3. 페이지 폴트 핸들러는
    1. *접근한 페이지를 다른 장소로 복사*하고,
    2. *쓰려고 한 프로세스에 할당*한 후
    3. 내용을 다시 작성합니다.
4. 부모 프로세스, 자식 프로세스 각각 공유가 해제된 페이지에 대응하는 페이지 테이블 엔트리를 업데이트합니다.
    - 쓰기를 한 프로세스 쪽에 엔트리는 새롭게 할당된 물리 페이지를 맵핑하여 쓰기를 허가합니다.
    - 다른 쪽 프로세스의 엔트리에도 쓰기를 허가합니다.

### swap

저장 장치의 일부를 일시적으로 메모리 대신 사용하는 방식입니다.

시스템의 물리 메모리가 부족한 상태가 되어 물리 메모리를 획득할 때에, 기존에 사용하던 물리 메모리의 일부분을 저장 장치에 저장하여 빈 공간을 만들어냅니다.
이때 메모리의 내용이 저장된 저장 장치상의 영역을 스왑 영역이라고 부릅니다.

### 계층형 페이지 테이블

### Huge page

## 기타

- [[컴퓨터 구조] 12. 가상 메모리](https://narakit.tistory.com/146?category=474839)
- [페이징](https://junsoolee.gitbook.io/linux-insides-ko/summary/theory/linux-theory-1)
