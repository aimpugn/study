# Examples

## 특정 시간 내 쿼리 조회

- `some_dt`,`some_tm`
    - 날짜, 시각 칼럼이 분리되어 있는 상황
    - 시간대 범위를 스캔
- 암호화된 값 `encrypted_value` 체크 필요
    - 찾고자 하는 값은 항상 정확히 일치해야 함
- `user_id`, `status` 등 체크 필요
    - 조건에 따라 부가 필터로만 사용될 수 있음

이때 인덱스는 `INDEX idx (some_dt, uuid)`만 걸려있고, 다른 인덱스 추가 없이 이 인덱스만 사용하는 경우를 가정합니다.

MySQL 인덱스는 *앞쪽 칼럼부터 순차적으로* 필터를 적용합니다.
따라서 `some_dt`로 먼저 범위를 좁히고, 다른 조건의 칼럼들은 후행 필터로 사용합니다.

인덱스를 최대한 활용하기 위해 `some_dt`에 대해 구간 조건(`BETWEEN`)을 사용합니다.
이 경우 다음과 같이 동작될 것으로 예상됩니다.

1. 우선 `some_dt BETWEEN T1 AND T2`라는 조건을 사용하면, 옵티마이저는 인덱스에서 *`T1` 이 첫 번째로 나타나는 리프 블록*을 찾아 갑니다.
2. 선두 칼럼에 `BETWEEN` 조건을 줬으므로, 날짜 구간 전체를 훓어야 합니다.

    그리고 이 시점에선 두 번째 칼럼 `uuid`로 점프할 수 없습니다.
    첫 칼럼이 동등(equality) 비교가 아니면, 그 뒤 순서를 탐색 키로 사용하지 못하기 때문입니다.

3. InnoDB 가 리프 레코드를 읽어 올 때마다 `uuid = ? AND encrypted_value = ?`로 필터링 합니다.

단, 결국 *무엇을 먼저 두느냐는 "실제 선택도, 쿼리 빈도"로 결정*합니다.
`EXPLAIN`, `ANALYZE`로 확인하는 것이 가장 좋습니다.

우선 24 시각 내부(같은 날) 범위라면 다음과 같은 쿼리를 작성할 수 있습니다.

```sql
WHERE some_dt = '20250420'
  AND some_tm BETWEEN '233607' -- 5분 전
                  AND '234107' -- 현재
  AND encrypted_value = 'Aa1Bb2Cc3Dd4Ee5=='
LIMIT 1;
```

MySQL은 `칼럼 BETWEEN low AND high`를 `low <= 칼럼 AND 칼럼 <= high`로 해석합니다.
즉, *범위 조건*은 `BETWEEN`와 `>= ... AND < ...` 모두 동일한 실행계획을 사용하기 때문에,
상한 포함/미포함 의도만 맞추면 됩니다.

다만 *상한(혹은 하한)만* 쓰면 다른 조건부터 인덱스를 써먹지 못할 수 있으니 꼭 *완전한 구간*을 주는 것이 좋습니다.

두 칼럼 조합을 한 번에 비교하려면 *튜플 비교*를 활용할 수 있습니다.
다만 인덱스를 타지 않는 것으로 보입니다.

```sql
WHERE (some_dt, some_tm) BETWEEN ('20250420','233607')
                             AND ('20250420','234107')
```

만약 날짜가 넘어갈 수 있는 5 분 전 범위라면:
1. 범위를 둘로 분할합니다. (전날 23:55:00 ~ 24:00 ) + (오늘 00:00 ~ 00:05 )

    ```sql
    WHERE encrypted_value = 'Aa1Bb2Cc3Dd4Ee5=='
    AND (
        (some_dt = '20250419' AND some_tm >= '235607')  -- 23:56:07
        OR (some_dt = '20250420' AND some_tm <= '000107')  -- 00:01:07
    )
    LIMIT 1;
    ```

    `LIMIT 1`은 첫 행을 찾은 순간 검색을 멈추기 때문에 디스크, CPU를 아낄 수 있습니다.
    따라서 "있냐, 없냐"만 확인할 경우 가급적 사용하는 것이 좋습니다.

2. 또는 *`UNION ALL`*, *`OR`* 두 식으로 표현합니다.

    `OR` 로 뒤섞여 있던 조건을 여러 개의 `SELECT ... UNION ALL ...` 형태로 분할하면,
    옵티마이저는 각 서브쿼리를 독립적인 단위로 보고 필요한 인덱스만 골라 훨씬 단순한 플랜을 구성할 수 있습니다.

    ```sql
    SELECT *
    FROM log_table
    WHERE some_dt = '2025-04-21'
        AND ( uuid = 'uid1' OR uuid = 'uid2' );
    ```

    위와 같은 경우 `uuid` 에 두 개의 값이 들어오니 인덱스를 두 번 탐색해야 한다고 판단하게 됩니다.
    따라서 Index Merge(UNION) 똔느 범용 범위 스캔 같은 복잡한 플랜을 짜게 됩니다.
    이 경우 리프 페이지를 두 번 이상 탐색하고, 결과를 합치거나 중복 검사를 해야 합니다.
    그리고 LIMIT, ORDER BY 같은 연산을 앞당기기 어렵습니다.

    ```sql
    SELECT *
    FROM log_table
    WHERE some_dt = '20250421'
        AND uuid = 'uid1'

    UNION ALL

    SELECT * F
    ROM log_table
    WHERE some_dt = '20250421'
        AND uuid = 'uid2';
    ```

    반면 이렇게 서로 다른 쿼리로 나누면, 각 SELECT에 대해 따로 인덱스를 탐색합니다.
    두 SELECT 모두 `INDEX(some_dt, uuid)` 인덱스를 완전 동치 조건으로 사용할 수 있으므로 탐색 키가 단일 범위로 결정될 수 있습니다.
    따라서 `some_dt = '20250421' AND uuid = 'uid2'`에 대한하는 리프 엔트리 한 개만 읽고, 바로 데이터 페이지 한 번을 마저 읽고 끝납니다.

참고로 빈도수가 낮은 칼럼은 굳이 인덱스를 안 걸어도 됩니다.
`status` 나 `user_id` 조건이 가끔 붙는 정도라면 *커버링 인덱스*가 아니어도 괜찮습니다.

## 캐시 히트 vs 인덱스

> 인덱스가 있으면 오래된 10 건을 읽을 때와 최근 1000 건을 읽을 때, 실제로 어느 쪽이 더 빠를까?

결국 인덱스가 걸려 있으면 '데이터가 새것이냐 오래되었느냐'보다는 '어떤 값으로 찾느냐'가 성능을 좌우합니다.

다만 *버퍼 풀(캐시)*과 *클러스터링(물리적 정렬)* 같은 요소가 가끔 체감 속도를 바꿀 수 있습니다.

B+Tree 인덱스를 통해 탐색할 때 다음과 같은 행동들이 이뤄집니다.
- "값을 키로 삼아" B+Tree 깊이(보통 3~4 단계)만큼 내려가서 "리프 페이지"를 찾습니다.

    이 탐색 과정은 "데이터가 언제 들어왔는지"와 무관합니다.
    오래된 10건이든 최근 1000건이든, "찾을 리프 노드"만 결정되면 끝입니다.

- 리프 페이지 내부에서 필요한 레코드를 ("=" 10 건​ or ​1000 건) 스캔해 갑니다.
    당연히 해당하는 10 건만 필터링하면 되므로 10건이 훨씬 빠릅니다.

하지만 가끔 1000이 빨라 보이는 이유는 무엇일까?
1. 버퍼 풀 히트

    최근에 `INSERT 된` 페이지들은 "아직 버퍼 풀"에 올라와 있을 확률이 높습니다.

    B+Tree 루트, 내부 노드는 자주 쓰이니 항상 캐시돼 있지만, 리프 페이지나 실제 데이터 페이지는 "최근 쓰기/읽기"가 곧 "캐시 적중"을 뜻합니다.

    그래서 "오래돼서 디스크에만 남아 있던 10건" vs "방금 써서 메모리에 남은 1000건"이라면 접근 속도 차이가 체감될 수 있습니다.

2. 자동 클러스터링(Primary Key 순)

    InnoDB의 클러스터형(Primary) 인덱스는 *PK 값 순서로 데이터 페이지를 배치*합니다.

    만약 PK를 타임스탬프 계열로 잡아 놨다면 "신규 레코드는 전부 마지막 페이지 근처"에 붙습니다.
    따라서 "최근 1000건"이란 말은 "물리적으로 연속된 페이지 몇 개"에 몰려 있을 가능성이 큽니다.

    반대로 1년에 걸쳐 흩어진 10건은 여러 페이지를 건너뛰며 점찍혀 있을 수 있으니, 페이지를 더 많이 읽어야 해서 느려질 가능성도 있습니다.

## 인덱스와 칼럼 가공

> 가령 `STR_TO_DATE('20250421', '%Y%m%d')`라고 하면 '20250421'이 `DATE` 타입으로 나옵니다.
> db에 2025-04-21 `DATE` 타입으로 저장되어 있고 해당 칼럼에 대해 인덱스가 걸려 있다고 할 때, `STR_TO_DATE('20250421', '%Y%m%d')`로 검색하면 가공으로 봐서 인덱스를 안 타는 걸까?

가공(함수 또는 연산 등)이 "칼럼 쪽" 에 붙었느냐, 아니면 "상수 쪽"에 붙는지가 핵심입니다.

상수만 가공할 때, 인덱스 그대로 탑니다.

```sql
-- some_dt 는 DATE 타입, 인덱스가 잡혀 있음
SELECT *
FROM log
-- 조건식이 "칼럼 = (상수 가공)" 형식인 경우, sargable(검색 가능)하다고 합니다.
WHERE some_dt = STR_TO_DATE('20250421','%Y%m%d');
```

- `STR_TO_DATE('20250421','%Y%m%d')`는 *쿼리를 파싱할 때 한 번 계산*돼서 결국 `WHERE some_dt = '2025‑04‑21'` 과 똑같이 동작합니다.
- *칼럼 값은 그대로고, 비교 값만 바뀌므로* B+트리는 정확한 리프부터 검색할 수 있습니다.
- 조건식이 "칼럼 = (상수 가공)" 형식이면 "가공"이라 말하지 않고 *[sargable(검색 가능)](https://kingged-uni.tistory.com/11)* 하다고 합니다.

반면, 칼럼을 가공하면 시작점을 잡지 못합니다.

```sql
-- 칼럼 쪽에 함수가 붙어 버린 예
SELECT *
FROM log
WHERE DATE(some_dt) = '2025‑04‑21';
```

- `DATE(some_dt)` 는 *행마다 호출돼야* 결과가 나옵니다.
- 인덱스에 저장돼 있는 건 '2025‑04‑21'이지, `DATE()` 결과가 아닙니다.
- 그래서 옵티마이저는 리프 어디서 시작해야 하는지를 모른 채 인덱스 전체 스캔(`type: index`)이나 테이블 풀스캔(`ALL`)을 하게 됩니다.

이는 `LEFT` 같이 문자열 가공도 같습니다.
`LEFT(encrypted_vl,3) = 'ABC'` 처럼 칼럼 문자열을 잘라서 비교하면 역시 "가공된 키"가 트리에 없으니 전체 범위를 훑습니다.

"가공해도 인덱스 타게" 하는 두 가지 방법이 있습니다.

1. 함수 기반(Functional) 인덱스

    칼럼이 아니라 "함수 결과"를 미리 저장해 둡니다.
    이는 *MySQL 8*부터 지원합니다.

    ```sql
    ALTER TABLE log
        ADD INDEX idx_dt_yyyymm ( DATE(some_dt) );
    ```

2. 생성(가상) 칼럼 + 일반 인덱스

   ```sql
   ALTER TABLE log
        ADD COLUMN some_dt_yyyymm INT AS (YEAR(some_dt)*100 + MONTH(some_dt)) STORED,
        ADD INDEX idx_dt_yyyymm (some_dt_yyyymm);
   ```

   쿼리는 `WHERE some_dt_yyyymm = 202504` 로 바꿉니다.

따라서, "상수에 함수를 적용"하는 경우 인덱스가 그대로 사용됩니다.
반면, 칼럼에 함수를 적용하면 인덱스가 시작점을 못 잡아 정상 사용이 불가능합니다.
그럼에도 칼럼에 함수를 적용하고 싶다면 "함수 기반 인덱스"나 "생성 칼럼"을 사용합니다.

## EXPLAIN ANALYZE 읽기

`EXPLAIN ANALYZE`는 실행계획을 실제로 실행해본 결과입니다.

```log
-> Limit: 200 row(s) (cost=2246 rows=200) (actual time=0.696..13.3 rows=200 loops=1)
    -> Filter: ((table1.some_column = 'test')
                AND (table1.some_tm BETWEEN '160000' AND '170000'))
               (cost=2246 rows=541) (actual time=0.695..13.3 rows=200 loops=1)
        -> Index lookup on table1 using table1_idx
           (some_dt = '20250421')
           (cost=2246 rows=48656) (actual time=0.678..12.6 rows=1146 loops=1)
```

1. Index lookup on table1 using table1_idx
    - InnoDB B tree에서 `table1_idx`(선두 컬럼이 `some_dt`)로 `some_dt = '20250421'` 범위를 찾아 내려갑니다.
    - `(cost=2246 rows=48656) (actual time=0.678..12.6 rows=1146 loops=1)`
        - 추정치 `rows=48656` 은 통계 정보에 기반하여 "같은 날짜 레코드가 그 정도 있을 것이다"라는 예상입니다.
        - 하지만 실제 읽어 온 리프 레코드(`rows`)는 1146건입니다.
        - `actual time=0.678..12.6`
            - 0.678 ms 에 찾기 시작했고
            - 12.6 ms 까지 리프 블록들을 순차로 읽어 나갔다는 뜻입니다.

2. Filter 단계
    - 인덱스는 현재 `some_dt` 하나만 포함합니다. 따라서 `table1.some_column = 'test'`와 `table1.some_tm BETWEEN '160000' AND '170000'` 두 조건을 만족하는지는 리프 레코드를 메모리에 풀어 놓은 뒤에야 검사할 수 있습니다.
    - 이때 InnoDB는 *Index Condition Pushdown* (ICP) 을 적용합니다. 즉 디스크에서 리프 블록을 읽어 올 때 `table1.some_column`과 `table1.some_tm` 값을 미리 보고 조건을 통과하지 못하면 해당 레코드를 아예 MySQL 레이어로 올리지 않습니다.
    - 추정치 `rows=541`은 인덱스 통계로 미뤄 봐서 두 조건을 통과할 레코드가 절반쯤 될 거라는 예측이고, 실제는 200건입니다. 이는 통계가 낡았거나 컬럼의 데이터 분포가 치우쳐 있을 때 흔히 보이는 오차라고 합니다.

3. Limit
    - `LIMIT 200` 때문에 옵티마이저는 `WHERE` 절에 맞는 레코드를 최대 200건만 필요로 한다는 것을 알고 있으므로 Filter 단계가 200건을 찾아내면 탐색을 중단합니다.
    - 1146건 전체를 읽고 나서 200건만 건져낸 것이 아니라, 200건을 확보하자마자 멈췄기 때문에 12.6 ms 정도 소요되고 끝났습니다.

4. 그 외 지표
    - `cost`: Optimizer Cost Model로 추산한 I/O 비용입니다. 시간 단위가 아니며 서버 설정, 통계 품질에 따라 달라집니다.
    - `rows`: 통계에서 계산한 예상 레코드 수입니다. 가령 `BETWEEN` 은 *범위 절반* 정도로, `LIKE 'abc%'`는 *카디널리티 / 100* 정도로 잡습니다.
    - `actual time`:
        - Parser 에서 Execution Engine 으로 넘어간 뒤, 해당 노드가 첫 row 를 출력하기까지와 마지막 row 를 출력했을 때 시간입니다.
        - 각 actual time 은 누적되거나 직렬화되지 않습니다. 서로 포함관계일 뿐, 추가적인 소요 시간이 아닙니다.
        - 가장 바깥 노드의 `actual time=0.696..13.3`에서 13.3이 실제 실행 시간입니다.
    - `loops`: Nested Loop Join 등에 들어갔을 때 몇 번 다시 실행됐는지를 나타냅니다.

이러한 지표는 계획상으로는 빨라야 하지만 실제로는 실행이 느려졌을 때, `actual time`, `rows`, `loops` 등을 함께 봐서 어디에서 시간이 밀리는지를 판단하는 데 도움이 됩니다

예를 들어,
- 리프 노드에서 `actual rows = 10만`, `actual time = 100ms`
- 필터 노드에서 `rows = 100`, `actual time = 600ms`

이러한 경우 리프가 너무 많은 데이터를 가져온 후, 위쪽 필터가 대부분을 걸러낸 것이라고 볼 수 있습니다.
이런 경우 *필터 조건을 인덱스로 내려야 한다*는 힌트가 됩니다.

현재 인덱스는 `(some_dt)` 하나만 잡혀 있습니다. 그 결과 트리 탐색은 `some_dt` 값으로만 좁혀 들어갑니다. 그리고 날짜가 같더라도 다른 조건이 맞지 않는 레코드는 *리프 페이지마다 검사해야* 합니다.

조건 순서는 중요합니다. 선두 컬럼이 동등(`=`) 조건일 때만 그 뒤 컬럼들을 탐색 키로 사용합니다.
지금처럼 필터에서 other 컬럼이 모두 등호거나 범위여도 인덱스 키 자체가 가지고 있지 않으면 "탐색 구간"을 더 줄일 방법이 없습니다.

성능을 더 끌어올리기 위해서는 다음과 같은 방법들을 고려해볼 수 있습니다.

1. 날짜, 시간, 컬럼을 모두 포함하는 복합 인덱스

    ```sql
    CREATE INDEX idx_dt_col_tm ON table1 (some_dt, some_column, some_tm);
    ```

    - `some_dt` 와 `some_column` 이 모두 동등 조건이므로 트리에서 leaf range 가 거의 0에 수렴합니다.
    - 그 상태에서 `some_tm BETWEEN ...` 범위가 즉시 적용되어 리프 탐색량도 극단적으로 줄어듭니다.
    - `LIMIT 200` 이라면 수백 microsecond 안쪽으로 끝나는 경우도 많습니다.

2. 날짜 컬럼 하나에 조건이 몰려 있을 때 분할

    very selective date 라면 굳이 시간과 다른 컬럼을 인덱스에 추가하지 않아도 충분할 수 있습니다.
    다만 현재 예시는 "같은 날짜 레코드가 5만 건"이므로 복합 인덱스가 큰 차이를 냅니다.

3. 통계 갱신

    인덱스가 있어도 통계가 낡으면 `rows` 예측이 어긋나 잘못된 플랜을 고를 위험이 커집니다.
    특히 날짜처럼 "새로운 값이 계속 늘어나는" 컬럼은 `ANALYZE TABLE table1` 으로 자주 통계를 새로 짜 주는 것이 좋습니다.
