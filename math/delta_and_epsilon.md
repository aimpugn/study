# Delta and Epsilon

- [Delta and Epsilon](#delta-and-epsilon)
    - [수학에서의 Epsilon과 Delta](#수학에서의-epsilon과-delta)
        - [수학적 표현](#수학적-표현)
    - [Epsilon과 Delta 정의 (미적분학에서의 연속성)](#epsilon과-delta-정의-미적분학에서의-연속성)
        - [Epsilon과 Delta의 의미](#epsilon과-delta의-의미)
        - [연속성이란?](#연속성이란)
        - [가까운 값들이란?](#가까운-값들이란)
    - [Epsilon-Delta의 개발에서의 의미](#epsilon-delta의-개발에서의-의미)
        - [부동소수점 비교](#부동소수점-비교)
        - [정밀도 요구](#정밀도-요구)
            - [비용 함수와 도함수](#비용-함수와-도함수)
            - [도함수의 유도](#도함수의-유도)
        - [함수 정의에서의 활용](#함수-정의에서의-활용)
    - [기타](#기타)

## 수학에서의 Epsilon과 Delta

Epsilon(ε)과 Delta(δ)는 주로 **해석학**(Analysis)이라는 수학 분야에서 사용되는 개념입니다.
특히 **미적분학**과 **실해석학**에서 중요하게 다루어집니다.

Epsilon-Delta 방법은 19세기 수학자 Karl Weierstrass에 의해 공식화되었습니다.
이 방법은 이전의 직관적이고 기하학적인 접근 방식을 대체하여, 수학적 해석을 더욱 엄밀하게 만들었습니다

함수의 행동을 정밀하게 기술하는 데 사용되며, 다음과 같은 여러 성질들을 명확하게 정의하고 분석하는 데 사용됩니다.
- 함수의 연속성
- 극한
- 미분 가능성 등

> 함수의 행동이란?
>
> 함수의 행동은 **입력 값**(즉, 함수에 전달된 값)에 따라 **출력 값**(함수가 반환하는 값)이 어떻게 변하는지를 의미합니다.
> 수학에서 "함수의 행동"이라는 표현은 주어진 함수가 특정 조건이나 범위 내에서 어떤 식으로 동작하는지를 분석하는 데 사용됩니다.

델타와 엡실론은 함수의 연속성이나 극한을 정의할 때 "임의로 작은 양"을 표현하는 데 사용됩니다.
- **Epsilon (ε)**:

    함수의 출력값(y축)에서 허용되는 아주 작은 오차 또는 근사값을 나타냅니다.

- **Delta (δ)**:

    함수의 입력값(x축)에서 허용되는 아주 작은 변화량을 나타냅니다.

### 수학적 표현

함수 $f(x)$의 극한을 $\epsilon-\delta$ 언어로 표현하면 다음과 같습니다:

lim(x→a) f(x) = L ⇔ ∀ε > 0, ∃δ > 0 such that |f(x) - L| < ε whenever 0 < |x - a| < δ

여기서:
- ∀ε > 0 는 "모든 양수 $\epsilon$에 대해"
- ∃δ > 0 는 "어떤 양수 $\delta$가 존재하여"
를 의미합니다.

예를 들어, f(x) = x^2의 x = 2에서의 연속성을 $\epsilon-\delta$ 방법으로 증명하면 다음과 같습니다.

1. f(2) = 4이므로, 우리는 |x^2 - 4| < ε임을 보여야 합니다.
2. |x^2 - 4| = |(x+2)(x-2)| ≤ |x+2| · |x-2| < 6δ (x가 2에 충분히 가까울 때)
3. 따라서 $\delta = min(1, \epsilon/6)$로 선택하면 됩니다.

이 예시는 $\delta$를 $\epsilon$의 함수로 명시적으로 표현할 수 있음을 보여줍니다.

## Epsilon과 Delta 정의 (미적분학에서의 연속성)

- **극한**:

    수열의 극한도 ε-N 방법으로 정의되며, 이는 $\epsilon-\delta$ 방법의 이산적 버전입니다.

    함수 $f(x)$가 $x$가 $c$에 접근할 때 $L$로 접근하는 것을 보이기 위해,
    모든 $\epsilon > 0$에 대해 $|f(x) - L| < \epsilon$이 성립하는 $x$의 범위를 찾을 수 있어야 합니다.

    이 범위는 $|x - c| < \delta$로 표현됩니다.

- **연속성**:

    *함수 f가 점 a에서 연속이라는 것*은 $\epsilon-\delta$ 정의를 만족한다는 것과 동치입니다.

    연속성은 모든 점에서 극한이 존재하고 그 값이 함수의 실제 값과 일치하는 것을 의미합니다.
    여기서도 $\epsilon$과 $\delta$의 관계가 적용됩니다.

- **함수의 미분 가능성**

    함수의 미분 가능성도 $\epsilon-\delta$ 언어로 정의될 수 있습니다.

### Epsilon과 Delta의 의미

- **Epsilon (ε)**: *함수 출력의 허용 가능한 차이*

    주어진 함수의 값과 목표하는 값(혹은 극한값) 사이의 허용 오차를 의미합니다.

    이 값은 다음과 같은 곳에 사용됩니다:
    - 함수의 연속성을 검증
    - 함수가 특정 값을 얼마나 정확히 근사할 수 있는지를 판단

- **Delta (δ)**: *입력 값의 허용 가능한 차이*

    주어진 오차 $\epsilon$을 보장하기 위해 $x$의 값이 가질 수 있는 허용 범위를 의미합니다.

    함수가 특정한 $c$에서 연속일 때, $\epsilon$이 주어지면 $|x - c| < \delta$가 되어야 합니다.

### 연속성이란?

함수가 연속이라는 것은 그 함수가 매끄럽게 변화하며, 특정 점에서 갑작스런 변화를 보이지 않는다는 것을 의미합니다.
이를 정밀하게 표현하기 위해 $\epsilon$-$\delta$ 정의가 사용됩니다.

함수의 연속성을 엄밀하게 표현한다면:

함수 $f(x)$가 $x = c$에서 **연속**이려면,
- 모든 $\epsilon > 0$에 대해,

    $\epsilon$은 함수의 출력 값 $f(x)$와 $f(c)$ 사이의 *허용 오차*를 나타냅니다.
    $\epsilon$은 아주 작은 값일 수 있으며,
    함수가 연속이라면 얼마나 작은 $\epsilon$이 주어지더라도 그에 맞는 $\delta$를 찾을 수 있어야 합니다.

    즉, $\epsilon$은 *함수 출력의 허용 가능한 차이*입니다.
    이는 $f(x)$가 $f(c)$에 얼마나 가까워야 하는지를 정해줍니다.

- 특정 $\delta > 0$가 존재하여

    $\delta$는 입력 값 $x$와 $c$ 사이의 허용 범위를 나타냅니다.
    $\delta$는 주어진 $\epsilon$에 따라 정해지며, $x$가 $c$에서 벗어나도 되는 최대 범위를 의미합니다.

    즉, $\delta$는 *입력 값의 허용 가능한 차이*입니다.
    이는 $x$가 $c$에서 얼마나 벗어나더라도 $f(x)$가 여전히 $f(c)$에 가까운지를 보장하는 역할을 합니다.

- $|x - c| < \delta$이면

    $x$가 $c$로부터 $\delta$(*입력 값의 허용 가능한 차이*) 이내에 있는지를 확인합니다.
    $x$가 $c$에 매우 가까운 값일 때만 이 조건이 만족됩니다.

    즉, $x$가 $c$로부터 얼마나 떨어질 수 있는지를 제한하며, 이는 $\delta$에 따라 결정됩니다.

- $|f(x) - f(c)| < \epsilon$이 성립해야 합니다.

    이 조건은 $x$가 $c$에 충분히 가까울 때, $f(x)$가 $f(c)$에 충분히 가까운지를 확인합니다.
    이때 차이가 $\epsilon$보다 작아야 함을 의미합니다.

    $f(x)$가 $f(c)$에 가까운지 여부는 $\epsilon$(*함수 출력의 허용 가능한 차이*)에 의해 결정되며,
    이는 함수가 해당 점에서 "뛰지 않고" 매끄럽게 이어진다는 것을 의미합니다.

여기서 함수가 $x = c$에서 **연속**이라는 것은,
단순히 $x$와 $c$가 같은 경우 외에 $x$가 $c$에 매우 **가까운 값들을 가질 때**,
즉 $x$가 $c$에 매우 가깝지만 같지는 않은 값들을 가질 때,
$f(x)$의 값도 $f(c)$에 매우 가까워진다는 의미입니다.(연속성)

즉, 입력 $x$가 $c$에 가까워지면,
출력 $f(x)$도 자연스럽게 $f(c)$에 가까워지며,
이 과정에서 중간에 불연속적인 "뛰어넘기" 없이 매끄럽게 변화한다는 것을 뜻합니다.

이 조건들은 함수의 값이 입력에 따라 "갑작스럽게 변하지 않고", 부드럽게 이어지며 특정 점에서 연속적인지를 보장하기 위한 것입니다.
특히, 이러한 수학적 정의는 함수의 극한을 다룰 때 필수적입니다.
*어떤 점에서 함수가 연속*이라면, *그 점에서 함수의 극한값이 실제 함수의 값과 일치해야* 합니다.
이 정의는 이러한 연속성을 보장하는 역할을 합니다.

> **연속성의 중요성**:
>
> 연속성은 함수의 행동을 이해하는 데 핵심적인 개념입니다.
>
> 예를 들어, 함수 $f(x)$가 $x = c$에서 연속이면, $x$가 $c$에 가까워질 때 $f(x)$의 값도 $f(c)$에 가까워져야 합니다.
> 이는 *함수의 출력이 갑작스러운 변동 없이 일정하게 변화함을 보장*합니다.
>
> 수학적 분석에서 함수의 연속성을 확인하는 것은, 극한을 다룰 때 매우 중요합니다.
> 극한을 다룰 때, *입력 값이 특정 값에 가까워지면, 출력 값이 특정한 값으로 수렴하는지를 확인*하게 됩니다.
> 이때 함수가 연속이라면 극한과 함수의 실제 값이 일치하게 됩니다.

### 가까운 값들이란?

1. **접근 (Approach)**:

    연속성은 함수가 특정 점에서 매끄럽게 이어지는지를 확인하기 위한 개념입니다.
    이를 위해서는 $x$가 $c$에 다가가는 상황, 즉 $x$가 $c$에 점점 가까워질 때를 고려해야 합니다.

    $x$가 $c$에 접근할 때 $f(x)$가 $f(c)$에 가까워지는지, 그렇지 않으면 다른 값으로 튀는지를 확인하는 것입니다.

2. **경계 근처의 값들**:

    수학에서는 특정한 점에서의 함수의 거동을 분석할 때, 그 점의 좌우에서 함수가 어떻게 행동하는지를 살펴봅니다.

    예를 들어, $c = 2$에서의 연속성을 확인하기 위해 $x = 1.9$ 또는 $x = 2.1$ 같은 값들을 고려합니다.
    이러한 값들에서의 $f(x)$가 $f(2)$에 가까워지면, *함수는 그 점에서 연속*이라고 말할 수 있습니다.

3. **극한의 개념**:

    연속성은 극한의 개념과 밀접하게 관련되어 있습니다.

    함수 $f(x)$가 $x = c$에서 연속이라는 것은,
    $x$가 $c$에 가까워질 때 함수의 극한값이 $f(c)$와 동일함을 의미합니다.

    극한에서, $x$는 $c$에 매우 가까워지지만, 실제로는 $x$가 $c$와 같지 않을 수 있습니다.
    따라서 $x$가 $c$에 접근하는 모든 경우를 고려해야 합니다.

예를 들어,신이 어떤 온도를 측정하고 있다고 가정해 봅니다.
$x$는 측정 시점이고 $c$는 정오(12:00)입니다.
연속성의 의미는, 정오에 가까운 시점들(11:59, 12:01 등)에서 온도 측정값 $f(x)$가 정오의 온도 $f(c)$와 매우 비슷하다는 것을 의미합니다.
이 경우, 온도 변화가 매우 부드럽게 이루어진다고 말할 수 있습니다.

따라서 연속성에서 중요한 것은 $x$가 $c$에 접근할 때의 함수 값의 변화입니다.
$x$가 $c$에 "가까운" 값들을 가질 때 함수 $f(x)$가 $f(c)$에 근접하게 변한다는 것이 연속성을 결정짓는 핵심입니다.
이 때문에 $x = c$일 때뿐만 아니라, $x$가 $c$에 가까워질 때의 상황을 고려하는 것이 필수적입니다.

$f(x) = x^2$이 $x = 2$에서 연속인지 확인하기 위해, 모든 $\epsilon > 0$에 대해 $\delta$를 찾을 수 있는지를 검토합니다.

예를 들어, $f(x) = x^2$가 $x = 2$에서 연속인지 확인한다고 하면,
$\epsilon = 0.01$을 주었을 때,
이 차이를 만족하는 $\delta$가 존재하는지를 찾아야 합니다.

$|x - 2| < \delta$일 때, $|f(x) - 4| < 0.01$여야 합니다.
이를 통해 $x^2$ 함수가 $x = 2$에서 연속임을 확인할 수 있습니다.

## Epsilon-Delta의 개발에서의 의미

Epsilon ($\epsilon$)과 Delta ($\delta$) 개념은 다음과 같은 상황에 활용됩니다.
- **부동소수점 연산**과 **정밀도 요구**가 있는 경우

    계산 오차나 부동소수점 표현의 한계로 인해 작은 차이를 무시하고 두 값을 동일하다고 간주할 때 유용합니다.

- 함수나 알고리즘의 **정밀성 요구사항**을 정의하고, **오차 허용 범위**를 설정하는 경우

    함수가 특정 조건을 만족하는지를 평가할 때, $\epsilon$과 $\delta$는 입력과 출력의 변화 범위를 제한하는 데 사용할 수 있습니다.
    이는 특정 알고리즘의 안정성을 분석하거나 민감도를 조절할 때 유용합니다.

    정밀도를 요구하는 알고리즘이나 함수에서는 *입력 값의 미세한 변화가 출력에 큰 영향을 미치지 않도록 $\delta$를 정의*할 수 있습니다.

    예를 들어, 물리 시뮬레이션이나 금융 계산에서 작은 입력 오차가 전체 계산 결과에 미치는 영향을 제한하기 위해 이러한 개념을 활용할 수 있습니다.

### 부동소수점 비교

부동소수점 숫자를 비교할 때, $\epsilon$은 *두 값의 차이를 무시할 수 있는 아주 작은 값*으로 설정됩니다.
이는 두 값이 *정확히 일치하지 않더라도, 충분히 가까운 값을 가질 때 동등하다고 판단*하는 데 사용됩니다.

```go
package main

import (
    "fmt"
    "math"
)

// AlmostEqual checks if two floating point numbers are almost equal within an epsilon
func AlmostEqual(a, b, epsilon float64) bool {
    return math.Abs(a-b) <= epsilon
}

func main() {
    a := 0.1
    b := 0.1 + 1e-9

    // Set epsilon to a small value
    epsilon := 1e-8

    if AlmostEqual(a, b, epsilon) {
        fmt.Printf("a and b are considered equal within epsilon = %e\n", epsilon)
    } else {
        fmt.Printf("a and b are NOT equal within epsilon = %e\n", epsilon)
    }

    // Example with a more significant difference
    c := 0.1 + 1e-7

    if AlmostEqual(a, c, epsilon) {
        fmt.Printf("a and c are considered equal within epsilon = %e\n", epsilon)
    } else {
        fmt.Printf("a and c are NOT equal within epsilon = %e\n", epsilon)
    }
}
```

### 정밀도 요구

함수를 정의하거나 알고리즘의 결과를 평가할 때, $delta$는 *입력 값의 작은 변화에 대해 출력 값이 허용할 수 있는 변화 범위*를 나타냅니다.
이를 통해 시스템이 입력 값의 변화에 얼마나 민감하게 반응해야 하는지를 설정할 수 있습니다.
가령 물리 시뮬레이션에서 입력 값의 작은 변화가 결과에 얼마나 영향을 미치는지를 평가하고 조절할 수 있습니다.

예를 들어, 경사 하강법은 최적화 알고리즘으로, 비용 함수의 최소값을 찾기 위해 사용됩니다.
여기서 $\delta$는 학습률(Learning Rate)로 설정되어,
입력 값의 작은 변화(가중치의 변화)에 따른 출력(비용 함수 값)의 변화 허용 범위를 설정합니다.

학습률이 너무 크면 최적화 과정이 불안정해지고, 너무 작으면 최적화가 매우 느리게 진행됩니다.

```go
package main

import (
    "fmt"
    "math"
)

// 이 예제에서 비용 함수는 $f(x) = (x - 3)^2$로 정의됩니다.
// 이 함수의 최소값은 $x = 3$에서 발생합니다.
func costFunction(x float64) float64 {
    return math.Pow(x-3, 2)
}

// Gradient Descent 함수
// 초기 값 `initialX`에서 시작하여, 학습률 `learningRate`를 사용해 최적화합니다.
// 각 반복(iteration)에서 `x` 값은 비용 함수의 기울기(도함수)를 사용하여 업데이트됩니다.
//
// 여기서 매개변수 delta는 알고리즘이 얼마나 정밀하게 수렴해야 하는지를 설정합니다.
// 작은 delta 값은 더 많은 반복을 요구하지만, 더 정확한 결과를 얻을 수 있습니다.
func gradientDescent(initialX, learningRate, delta float64) float64 {
    x := initialX
    iteration := 0

    for {
        // 비용 함수 값 계산:
        // 각 반복(iteration)에서 현재 x 값과 그에 대응하는 비용이 출력되며,
        // 함수의 출력이 어떻게 변하는지, 입력 x 값에 따라 어떻게 최적화되는지를 추적할 수 있습니다.
        //
        // 이는 최적화 과정에서 함수가 수렴해가는 과정을 보여주며,
        // 알고리즘의 성능을 평가하는 데 중요한 역할을 합니다.
        cost := costFunction(x)
        fmt.Printf("Iteration %d: x = %f, cost = %f\n", iteration, x, cost)

        // 비용 함수의 도함수 (gradient)
        // 이 값이 양수이면 매개변수 `x`를 감소시키고, 음수이면 `x`를 증가시킵니다.
        gradient := 2 * (x - 3)

        // `learningRate`는 학습률로 도함수와 함께 매개변수가 얼마나 변경될지를 조절합니다.
        newX := x - learningRate*gradient

        // |newX - x| 값이 `delta`보다 작아지면 최적화가 수렴했다고 판단하고 반복을 종료합니다.
        if math.Abs(newX-x) < delta {
            break
        }

        x = newX
        iteration++
    }

    fmt.Printf("Gradient Descent converged after %d iterations\n", iteration)
    return x
}

func main() {
    initialX := 0.0
    learningRate := 0.1

    // 민감도 설정:
    // 입력 값의 작은 변화에 따른 출력 값의 변화 허용 범위를 정의하며, *수렴 조건*으로 사용됩니다.
    // 이는 알고리즘이 얼마나 정밀하게 수렴할지를 결정합니다.
    delta := 1e-6

    result := gradientDescent(initialX, learningRate, delta)
    fmt.Printf("Result: x = %f\n", result)
}
```

$\delta$ 값은 입력 값의 작은 변화에 대해 결과가 얼마나 민감하게 반응해야 하는지를 조절합니다.
- $\delta$ 값이 작으면 더 높은 정밀도를 얻을 수 있지만, 성능이 저하될 수 있습니다.
- $\delta$ 값이 크면 빠르게 수렴할 수 있지만, 최적화가 충분히 정확하지 않을 수 있습니다.

예를 들어, 경사 하강법에서는 $\delta$ 값이 작을수록 더 정확한 최적화를 추구하게 되지만, 더 많은 반복이 필요할 수 있습니다.

따라서 이 $\delta$ 값은 상황에 맞게 조정되어야 합니다.

#### 비용 함수와 도함수

함수 $f(x)$를 이해하기 위해서는 **Cost Function**과 **도함수**의 역할을 구분하는 것이 중요합니다.
이 둘은 최적화 알고리즘에서 서로 다른 목적을 갖습니다.
- 비용 함수: 모델의 오차를 측정하는 데 사용됩니다.
- 도함수: 모델의 오차를 최소화하기 위해 어떻게 움직여야 할지를 알려줍니다.

1. Cost Function (비용 함수)

    비용 함수는 현재의 모델이 얼마나 잘 수행되고 있는지 성능을 측정하는 함수입니다.
    특정 입력 값 $x$에 대해 출력 값 $f(x)$가 얼마나 목표와 차이가 나는지를 수치적으로 나타냅니다.
    이 값이 *작을수록 모델의 성능이 좋다*는 의미입니다.

    - **역할**:
        - **오차 측정**: 비용 함수는 모델의 예측 값과 실제 값 사이의 오차를 측정합니다. 최적화 알고리즘의 목표는 이 오차를 최소화하는 것입니다.
        - **최적화 대상**: 비용 함수를 최소화하는 것은 최적화 알고리즘의 핵심 목표입니다. 따라서 최적의 모델 파라미터를 찾기 위해 비용 함수를 반복적으로 계산합니다.

    예를 들어, 비용 함수가 $f(x) = (x - 3)^2$로 주어졌다고 가정하면, 이 함수는 $x = 3$에서 최소값 0을 가집니다.
    즉, $x$가 3일 때 오차가 최소라는 의미입니다.

    ```go
    func costFunction(x float64) float64 {
        return math.Pow(x-3, 2)
    }
    ```

2. Derivative (도함수, Gradient)

    도함수는 *비용 함수의 특정 지점에서의 기울기*("변화율")를 나타냅니다.
    이 기울기는 입력 값 $x$의 작은 변화가 출력 값 $f(x)$에 얼마나 영향을 미치는지를 보여줍니다.
    최적화 알고리즘에서 도함수는 *매개변수를 업데이트할 방향과 크기*를 결정하는 데 사용되며,
    이를 통해 목표 함수를 최소화하는 데 중요한 역할을 합니다.

    예를 들어, 경사 하강법은 비용 함수를 최소화하기 위해 매개변수를 반복적으로 업데이트하는 최적화 알고리즘입니다.
    여기서 도함수는 비용 함수의 기울기를 계산하고, 매개변수를 이 기울기의 반대 방향으로 조정합니다.
    즉, 비용 함수의 값을 줄이는 방향으로 매개변수를 조정해 나갑니다.
    - 도함수의 절대값이:
        - 크다면 매개변수를 크게 변화시킵니다
        - 작다면 매개변수를 조금씩 조정합니다.
    - 도함수의 부호가:
        - 양수라면 매개변수를 줄여서 비용 함수의 값을 줄입니다.
        - 음수라면 매개변수를 늘려서 비용 함수의 값을 줄입니다.

    이 과정을 통해 알고리즘은 비용 함수를 최소화하는 지점으로 수렴하게 됩니다.

    - **역할**:

        주로 **기울기를 기반으로 최적화 과정에서 매개변수를 업데이트**하는 데 있습니다.
        도함수를 사용하는 이유는 최적화 문제에서 목표 함수(예: 비용 함수)의 최소값을 찾기 위해 매개변수를 적절하게 조정하는 방법을 제공하기 때문입니다.

        - **최적화 방향 결정**:

            도함수는 비용 함수를 어떻게 조정해야 오차를 줄일 수 있는지를 알려줍니다.
            도함수는 목표 함수가 증가하는지 감소하는지를 나타내며, 이는 매개변수를 어떻게 조정해야 할지를 결정하는 데 중요한 정보를 제공합니다.
            - 기울기가 양수라면 $x$를 줄여야 합니다.
            - 기울기가 음수라면 $x$를 늘려야 합니다.

            예를 들어, 경사 하강법 경우:
            - 도함수가 양수인 경우, 함수 값이 증가하고 있으므로 매개변수를 감소시켜야 합니다.
            - 도함수가 음수인 경우, 함수 값이 감소하고 있으므로 매개변수를 증가시켜야 합니다.

            이 과정에서 도함수는 매개변수를 조정하여 *목표 함수의 값을 최소화하는 방향으로 이동*하게 합니다.
        - **학습률 조정**:

            도함수의 크기는 학습률(learning rate)과 함께 매개변수가 한 번의 업데이트에서 얼마나 이동할지를 결정합니다.
            - 도함수가 클수록 매개변수의 변화 폭이 커집니다.
            - 도함수가 작을수록 매개변수의 변화 폭이 작아집니다.

            최적화 과정에서 학습률을 도함수와 함께 조절하여, 너무 빠르게 수렴하지 않도록 하거나, 너무 느리게 수렴하는 것을 방지합니다.
            도함수가 작아질수록, 매개변수 변화량도 작아지며, 이는 더 정밀한 최적화를 가능하게 합니다.

        - **최소값 탐색**: 도함수를 사용하여 비용 함수의 최소값을 찾아갑니다. 이는 비용 함수를 직접 최소화하는 것보다 더 효율적입니다.

        - **수렴 판단**:

            도함수가 0에 가까워질 때, 최적화 과정에서 매개변수가 거의 변하지 않게 됩니다.
            이는 목표 함수가 로컬 최소값 또는 전역 최소값에 도달했음을 의미할 수 있습니다.
            이 시점에서 최적화 알고리즘은 수렴했다고 판단하고 종료될 수 있습니다.

            도함수의 값이 작아지는 것은 목표 함수가 평평해지고 있다는 신호이므로, 이때는 더 이상 매개변수를 크게 변화시키지 않아도 됩니다.

    예를 들어, $f(x) = (x - 3)^2$의 도함수는 $f'(x) = 2(x - 3)$입니다.
    이 도함수를 사용하여 최적화 과정에서 $x$ 값을 갱신합니다.

    ```go
    gradient := 2 * (x - 3)
    newX := x - learningRate*gradient
    ```

#### 도함수의 유도

주어진 함수 $f(x) = (x - 3)^2$의 도함수 $f'(x)$를 구하는 과정은 미적분학의 기본적인 원칙을 따릅니다.
도함수는 함수의 변화율을 나타내며, 특정 점에서의 기울기를 계산합니다.

- 함수: $f(x) = (x - 3)^2$
- 도함수:

    $f'(x)$는 $f(x)$의 변화율을 나타내며, 이는 $x$의 작은 변화에 대해 $f(x)$가 얼마나 변하는지를 나타냅니다.

    도함수는 일반적으로 다음과 같이 정의됩니다:

    $f'(x) = \lim_{\Delta x \to 0} \frac{f(x + \Delta x) - f(x)}{\Delta x}$

    그러나, 이 정의를 이용해 직접 계산하기보다는, 흔히 사용되는 미분의 규칙을 적용하여 계산할 수 있습니다.

- 도함수 계산 과정

    $f(x) = (x - 3)^2$는 합성 함수로 볼 수 있습니다.
    이는 $x$에 대한 다항식으로, 다음과 같은 규칙을 적용해 미분할 수 있습니다:

    **체인 룰(Chain Rule)**:

    합성 함수 $g(h(x))$의 도함수는 $g'(h(x)) \cdot h'(x)$로 표현됩니다.

    먼저, 함수 $f(x) = (x - 3)^2$를 $g(u) = u^2$ 및 $h(x) = x - 3$로 나눌 수 있습니다.

    1. **외부 함수 미분**: $g(u) = u^2$의 도함수는 $g'(u) = 2u$입니다.
    2. **내부 함수 미분**: $h(x) = x - 3$의 도함수는 $h'(x) = 1$입니다.

    그러므로, 체인 룰에 의해 $f'(x)$는 다음과 같이 계산됩니다:

    $f'(x) = g'(h(x)) \cdot h'(x) = 2(x - 3) \cdot 1 = 2(x - 3)$

    따라서, $f(x) = (x - 3)^2$의 도함수는 $f'(x) = 2(x - 3)$입니다.

### 함수 정의에서의 활용

함수가 특정 조건을 만족하는지 평가할 때, 입력 값의 작은 변화가 출력에 미치는 영향을 분석하고, 특정 기준을 충족하도록 설정할 때 사용됩니다.

가령 아래의 선형 회귀 모델을 최적화하는 예제는 비용 함수(손실 함수, CostFunction)를 최소화하기 위해 도함수(Gradient)를 사용합니다.
이 과정은 주로 경사하강법(Gradient Descent)을 통해 이루어지며, 이는 모델 매개변수에 따라 비용 함수의 기울기를 계산하고, 이를 바탕으로 매개변수의 값을 조정합니다:
- 비용 함수:

    모델이 예측한 값과 실제 값 사이의 오차를 측정하는 함수입니다.
    이 오차를 최소화하는 것이 모델 최적화의 목표입니다.

- 비용 함수의 도함수:

    도함수는 특정 지점에서 비용 함수의 변화율을 나타내며, 이를 통해 최적화 과정에서 매개변수를 조정합니다.
    도함수는 특정 지점에서의 기울기를 계산하여
    - 매개변수 기울기(m)와 절편(b)를 업데이트하고
    - 비용 함수의 값을 최소화합니다.

    이 과정에서 입력 값의 변화(매개변수의 변화)가 출력 값(비용 함수 값)에 미치는 영향을 제어하고,
    최적화가 올바른 방향으로 진행되도록 합니다.

    **최적화 과정에서 비용 함수의 최소값을 찾는** 방법:
    - **도함수**를 사용하여 함수의 매개변수와 결과 간의 민감도(입력 값의 작은 변화가 출력 값에 미치는 영향)를 조절합니다.
    - **도함수**를 사용하여 최적화 알고리즘이 **수렴**하는지를 평가합니다.

        수렴 조건인 $\delta$는 매개변수의 변화가 충분히 작아져 더 이상 유의미한 변화를 보이지 않을 때,
        최적화 알고리즘이 반복을 중단하도록 합니다.
        즉, 기울기와 절편이 더 이상 유의미하게 변화하지 않을 때 반복을 멈추는 기준이 됩니다.
        이로써 함수의 안정성과 최적화를 평가합니다.

```go
package main

import (
    "fmt"
    "math"
)

// 비용 함수:
// 모델의 예측이 실제 데이터와 얼마나 일치하는지를 측정합니다.
// 평균 제곱 오차(Mean Squared Error, MSE)를 비용 함수로 사용하여,
// 예측 $y$ 값과 실제 $y$ 값 사이의 차이(오차, error)의 제곱을 평균 내어 반환합니다.
//
// 여기서 오차란 알고리즘이 예측한 값과 실제 정답과의 차이를 의미합니다.
// 즉, 알고리즘이 정답을 잘 맞출수록 MSE 값은 작습니다.
// 반대로 MSE 값이 작을수록 알고리즘의 성능이 좋다고 볼 수 있습니다.
func costFunction(m, b float64, dataPoints []float64) float64 {
    totalError := 0.0
    for _, point := range dataPoints {
        x := point[0]
        y := point[1]
        predictedY := m*x + b
        totalError += math.Pow(predictedY-y, 2)
    }
    return totalError / float64(len(dataPoints))
}

// GradientDescent: 기울기와 절편을 조정하는 최적화 알고리즘
//
// 기울기(m)와 절편(b)를 업데이트하여 모델이 최적화되도록 합니다.
// 도함수(gradient)를 사용하여 기울기와 절편을 조정합니다.
// 도함수는 비용 함수의 기울기를 나타내며, 이를 통해 모델의 매개변수를 업데이트하여 비용을 최소화하는 방향으로 이동합니다.
func gradientDescent(m, b, learningRate float64, dataPoints []float64) (float64, float64) {
    mGradient := 0.0
    bGradient := 0.0
    N := float64(len(dataPoints))

    for _, point := range dataPoints {
        x := point[0]
        y := point[1]
        mGradient += -(2 / N) * x * (y - ((m * x) + b))
        bGradient += -(2 / N) * (y - ((m * x) + b))
    }

    newM := m - (learningRate * mGradient)
    newB := b - (learningRate * bGradient)
    return newM, newB
}

func main() {
    // 예제 데이터 포인트 (x, y)
    dataPoints := [][]float64{
        {1, 2},
        {2, 2.8},
        {3, 3.6},
        {4, 4.5},
        {5, 5.1},
    }

    // 초기 기울기(m)와 절편(b)
    m := 0.0
    b := 0.0

    // 학습률 (learning rate) 및 민감도(정밀도)를 설정
    learningRate := 0.01

    // 최적화가 수렴하는지를 결정하는 민감도(정밀도)로 설정됩니다.
    // 최적화 알고리즘이 언제 멈춰야 하는지를 결정하는 역할을 합니다.
    // 너무 많은 반복을 피하고, 적절한 시점에 학습을 종료할 수 있습니다.
    //
    // `delta` 값은 기울기와 절편이 더 이상 유의미하게 변화하지 않는지를 판단하는 데 사용됩니다.
    // 기울기(m)와 절편(b)의 변화량이 `delta` 이하로 작아지면 알고리즘은 수렴했다고 판단하고 반복을 종료합니다.
    delta := 1e-6 // 민감도 설정 (수렴 조건)

    // 반복하면서 최적화 진행
    for i := 0; i < 1000; i++ {
        newM, newB := gradientDescent(m, b, learningRate, dataPoints)

        // 기울기(m)와 절편(b)의 변화가 delta 이하일 경우 수렴했다고 판단
        if math.Abs(newM-m) < delta && math.Abs(newB-b) < delta {
            fmt.Printf("Gradient Descent converged after %d iterations\n", i)
            break
        }

        m = newM
        b = newB
    }

    // 최종 모델 평가
    finalCost := costFunction(m, b, dataPoints)
    fmt.Printf("Final model: y = %.2fx + %.2f\n", m, b)
    fmt.Printf("Final cost: %f\n", finalCost)
}
```

- **성능 평가**: 비용 함수는 모델의 성능을 평가하는 데 사용되며, 이를 통해 모델이 얼마나 잘 학습되었는지를 알 수 있습니다.
- **최적화 과정**: 도함수를 사용하여 모델의 매개변수를 조정함으로써 최적의 매개변수를 찾아가는 과정입니다. 이 과정에서 `delta`를 통해 알고리즘의 수렴을 조절하고, 효율적으로 학습이 이루어지도록 합니다.

## 기타

- Rudin, W. (1976). Principles of mathematical analysis (Vol. 3). New York: McGraw-hill.
- Grabiner, J. V. (1983). Who gave you the epsilon? Cauchy and the origins of rigorous calculus.
