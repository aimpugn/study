services:
  # References:
  # - https://docs.confluent.io/platform/current/installation/docker/config-reference.html
  kafka1:
    image: apache/kafka:latest
    container_name: kafka1
    ports:
      - "9092:9092" # 클라이언트 연결을 위한 포트 매핑
    environment:
      # 클러스터 내에서 브로커를 구분하기 위한 각 브로커의 고유 식별자입니다.
      # KAFKA_BROKER_ID: 1
      # KRaft 모드에서는 `KAFKA_BROKER_ID` 대신 `KAFKA_NODE_ID`를 사용하여 노드를 식별합니다.
      # 정수를 사용해야 합니다. 그렇지 않으면 다음과 같은 에러가 발생합니다.
      # ```
      # Exception in thread "main" org.apache.kafka.common.config.ConfigException: Invalid value kafka2 for configuration broker.id: Not a number of type INT
      # ```
      KAFKA_NODE_ID: 1
      # 노드의 역할을 지정합니다
      # - `broker`
      # - `controller`
      # - `broker,controller`
      KAFKA_PROCESS_ROLES: "broker,controller"
      # 브로커가 수신할 리스너를 정의합니다. 클라이언트와 컨트롤러 간의 통신을 설정하기 위해 필요합니다.
      # - 아이피 버전(IPv4, IPv6)이 서로 다르지 않다면, 리스너 이름과 포트는 유일해야 합니다.
      # - `0.0.0.0`은 모든 인터페이스에 바인드되는 것을 지정합니다.
      # `이름:값` 형식으로 설정합니다.
      #
      # References:
      # - https://kafka.apache.org/documentation/#brokerconfigs_listeners
      KAFKA_LISTENERS: "PLAINTEXT://kafka1:9092,CONTROLLER://kafka1:9093"
      # `listeners`(`KAFKA_LISTENERS`) 속성과 다른 경우, 클라이언트가 사용할 수 있도록 ZooKeeper에 게시할 리스너입니다.
      # - IaaS 환경의 경우, 브로커가 바인딩하는 인터페이스와 달라야 할 수 있습니다.
      # - 별도의 설정이 없다면 `listeners`(`KAFKA_LISTENERS`) 값이 사용됩니다.
      # - 그리고 `listeners`(`KAFKA_LISTENERS`) 설정과 달리 포트 중복이 가능합니다.
      #   따라서 한 리스너는 다른 리스너의 주소를 광고(advertise)하도록 구성할 수 있습니다.
      #   이는 외부 로드 밸런서가 사용되는 경우에 유용할 수 있습니다.
      #
      # References:
      # - https://kafka.apache.org/documentation/#brokerconfigs_advertised.listeners
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka1:9092"
      # `KAFKA_LISTENERS`에 정의된 리스너에 대한 security protocol 맵을 정의합니다.
      # 정의하지 않으면 다음과 같은 에러가 발생합니다.
      # ```
      # No security protocol defined for listener CONTROLLER
      #   at kafka.utils.CoreUtils$.listenerListToEndPoints(CoreUtils.scala:216)
      #   at kafka.server.KafkaConfig.listeners(KafkaConfig.scala:1104)
      #   ... 생략 ...
      # ```
      #
      # References:
      # - https://kafka.apache.org/documentation/#brokerconfigs_listener.security.protocol.map
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      # 컨트롤러가 사용하는 리스너 이름 목록입니다. 콤마로 구별됩니다.
      # KRaft 모드 경우 필수입니다.
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      # KRaft 모드에서 컨트롤러 선출을 위해 컨트롤러 정족수(quorum)를 구성하는 노드의 정보를 지정합니다.
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      # 내부 토픽의 복제 계수를 설정합니다.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      # 트랜잭션 상태 로그의 복제 계수를 설정합니다.
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      # 트랜잭션 상태 로그의 최소 ISR(In-Sync Replicas) 수를 설정합니다.
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      # 로그 데이터를 저장할 디렉토리를 지정합니다. 데이터의 영구 저장을 위해 필요합니다.
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      # Confluent 지원 메트릭 활성화 여부를 설정합니다.
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: false
    volumes:
      - ./.tmp/data/kafka1:/var/lib/kafka/data # 호스트에 데이터를 영구적으로 저장
      - ./init_kafka.sh:/init_kafka.sh  # 초기화 스크립트 매핑
    networks:
      - kafka-net # Kafka 네트워크에 연결
    command: [ "sh", "-c", "/init_kafka.sh" ]
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-cluster.sh", "cluster-id", "--bootstrap-server", "kafka1:9092"]
      interval: 3s
      timeout: 5s
      retries: 50

  kafka2:
    image: apache/kafka:latest
    container_name: kafka2
    ports:
      - "9093:9092"  # 컨테이너 내부의 9092 포트를 호스트의 9093 포트로 매핑
    environment:
      # KAFKA_BROKER_ID: 2
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://kafka2:9092,CONTROLLER://kafka2:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka2:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: false
    volumes:
      - ./.tmp/data/kafka2:/var/lib/kafka/data
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-cluster.sh", "cluster-id", "--bootstrap-server", "kafka2:9092"]
      interval: 3s
      timeout: 5s
      retries: 50

  kafka3:
    image: apache/kafka:latest
    container_name: kafka3
    ports:
      - "9094:9092" # 컨테이너 내부의 9092 포트를 호스트의 9094 포트로 매핑
    environment:
      # KAFKA_BROKER_ID: 3
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://kafka3:9092,CONTROLLER://kafka3:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka3:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
    volumes:
      - ./.tmp/data/kafka3:/var/lib/kafka/data
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-cluster.sh", "cluster-id", "--bootstrap-server", "kafka3:9092"]
      interval: 3s
      timeout: 5s
      retries: 50

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8888:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9092,kafka3:9092
    networks:
      - kafka-net

  # stdout으로 도커 로그를 출력하는 프로듀서
  producer:
    ports:
      - "9090:9090"
    build:
      context: producer
      dockerfile: Dockerfile
    container_name: producer
    # References:
    # - https://docs.docker.com/engine/logging/configure/
    # - https://docs.docker.com/reference/compose-file/services/#logging
    logging:
      driver: "json-file"  # default. https://docs.docker.com/engine/logging/drivers/json-file/
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - kafka-net
    depends_on:
      - vector  # Vector 서비스가 먼저 시작되도록 설정

  # 로그를 수집하고 파싱하여 Kafka로 전송하는 Vector 서비스
  vector:
    image: timberio/vector:latest-alpine
    container_name: vector
    volumes:
      - ./vector/config/transforms.parse_app_logs.vrl:/transforms.parse_app_logs.vrl
      # Vector 설정 파일(read only)
      - ./vector/config/vector.yaml:/etc/vector/vector.yaml:ro
      # vector.yaml 설정에 별도 docker_host 설정 없으면,
      # Docker 소켓 통해서 로그 수집하게 됩니다.
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - kafka-net
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy

  # Kafka에서 메시지를 수신하는 컨슈머
#  consumer:
#    image: openjdk:21
#    container_name: consumer
#    build:
#      context: ./consumer
#      dockerfile: Dockerfile
#    networks:
#      - kafka-net
#    depends_on:
#      - kafka1
#      - kafka2
#      - kafka3

networks:
  kafka-net:
    driver: bridge # 기본 브리지 네트워크 사용
